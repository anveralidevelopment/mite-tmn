# Монитор активности клещей - Тюмень

Веб-сервис для мониторинга активности клещей в Тюменской области с современным дизайном в стиле Bitrix24, ML-прогнозированием и расширенной аналитикой.

## Основные возможности

### Визуализация данных
- **Интерактивные графики** - динамика активности клещей по неделям с цветовой индикацией уровня риска
- **Интерактивная карта** - карта Тюменской области с маркерами активности клещей по локациям
- **Сравнение с предыдущими годами** - график сравнения активности за последние 4 года
- **Статистика** - текущая и прошлая неделя с количеством случаев и уровнем риска

### Machine Learning
- **Прогнозирование на 2026 год** - ML-модели (Linear Regression, Random Forest, XGBoost, LSTM, GRU) для прогнозирования активности
- **Автоматическая генерация новостей** - лента новостей, сгенерированная на основе анализа данных
- **Автоматическое переобучение** - модель переобучается после каждого обновления данных
- **Ensemble модели** - комбинация нескольких моделей для улучшения точности
- **AutoML** - автоматический выбор лучшей модели
- **A/B тестирование** - сравнение производительности разных моделей
- **Обнаружение аномалий** - выявление необычных паттернов в данных
- **Кластеризация локаций** - группировка районов по активности
- **Рекомендации по профилактике** - автоматическая генерация советов на основе данных

### Парсинг данных
- **Множественные источники**:
  - Роспотребнадзор (веб-сайт, RSS, поиск, новости)
  - Telegram канал
  - Администрация Тюмени (опционально)
  - VK группы (опционально)
  - Локальные новостные сайты (опционально)
  - Медицинские API (опционально)
  - Погодные API для улучшения прогнозов (опционально)
- **Умный парсинг** - автоматический поиск альтернативных URL при недоступности основного источника
- **Парсинг полных статей** - извлечение полного содержимого статей со страниц
- **Парсинг PDF документов** - поддержка OCR для извлечения текста из PDF
- **Selenium для JS-сайтов** - поддержка динамически загружаемого контента
- **Автоматическое извлечение локаций** - определение населенных пунктов из текста
- **Улучшенное извлечение дат** - поддержка различных форматов дат с валидацией
- **Проверка сезонности** - регистрация случаев только в сезон активности клещей (20 апреля - 10 октября)
- **Валидация данных** - проверка качества данных перед сохранением
- **Защита от дубликатов** - автоматическое обнаружение и обработка дублирующихся записей

### Поиск и фильтрация
- **Полнотекстовый поиск** - поиск по заголовкам и содержимому
- **Фильтры**:
  - По локации
  - По источнику данных
  - По уровню риска
  - По дате (начальная и конечная)
- **Динамическое обновление фильтров** - списки фильтров автоматически заполняются доступными значениями
- **Пагинация** - отображение источников данных по 10 записей с кнопкой "Показать еще"

### Экспорт данных
- **CSV** - экспорт в формат CSV с кодировкой UTF-8
- **Excel** - экспорт в Excel с форматированием и автошириной колонок
- **PDF** - генерация PDF отчетов с таблицами и графиками

### Уведомления
- **Email уведомления** - отправка уведомлений о всплесках активности
- **Telegram уведомления** - отправка сообщений в Telegram бот
- **Настраиваемые пороги** - настройка порогов для срабатывания уведомлений

### Хранение данных
- **PostgreSQL** - надежное хранение данных в реляционной БД
- **Индексы** - оптимизированные индексы для быстрого поиска
- **Кэширование Redis** - ускорение загрузки данных через Redis кэш
- **Автоматическое резервное копирование** - персистентные тома Docker

### Мониторинг и аналитика
- **Prometheus метрики** - экспорт метрик для мониторинга:
  - Количество HTTP запросов
  - Время выполнения запросов
  - Количество точек данных в БД
  - Попадания и промахи кэша
  - Ошибки парсинга
  - Количество ML прогнозов
- **Расширенная аналитика** - сравнение данных по годам, средние значения
- **Метрики качества ML** - R², RMSE, MAPE для оценки моделей

### API
- **RESTful API** - полный набор API endpoints
- **Swagger документация** - интерактивная документация API (`/api/docs`)
- **Rate limiting** - защита от перегрузки (200 запросов/день, 50/час)
- **CORS** - поддержка кросс-доменных запросов

### Интерфейс
- **Современный дизайн** - стиль Bitrix24 с синими и зелеными тонами
- **Темная тема** - переключение между светлой и темной темой
- **Адаптивный дизайн** - корректное отображение на мобильных устройствах
- **Интерактивные элементы** - карточки, графики, карты с hover-эффектами

### Автоматизация
- **Автоматическое обновление** - обновление данных раз в сутки (1440 минут, настраивается)
- **Автоматическое переобучение ML** - модель переобучается после обновления данных
- **Обработка ошибок** - автоматические повторы при сбоях парсинга
- **Проверка сезонности** - автоматическое отсеивание данных вне сезона активности клещей

## Структура проекта

```
mite-tmn/
├── src/                           # Исходный код приложения
│   ├── app.py                     # Flask приложение с API endpoints
│   ├── parser.py                 # Модуль парсинга данных из различных источников
│   ├── database.py                # Работа с PostgreSQL через SQLAlchemy
│   ├── ml_predictor.py            # ML модели для прогнозирования
│   ├── enhanced_ml_predictor.py   # Расширенные ML компоненты (LSTM, GRU, Ensemble и т.д.)
│   ├── cache_manager.py           # Управление Redis кэшем
│   ├── notifications.py            # Отправка уведомлений (Email, Telegram)
│   ├── export_manager.py          # Экспорт данных (CSV, Excel, PDF)
│   ├── swagger_docs.py            # Swagger документация API
│   ├── logger_config.py           # Настройка логирования
│   ├── data_verifier.py           # Проверка качества данных и сезонности
│   ├── vk_parser.py               # Парсинг VK групп
│   ├── local_news_parser.py       # Парсинг локальных новостных сайтов
│   ├── pdf_parser.py              # Парсинг PDF документов
│   ├── selenium_parser.py         # Парсинг JS-сайтов через Selenium
│   └── api_integrations.py        # Интеграции с внешними API (медицина, погода)
├── config/                        # Конфигурация
│   └── config.json                # Настройки приложения
├── docker/                        # Docker конфигурация
│   ├── Dockerfile                 # Образ приложения
│   └── docker-compose.yml         # Композиция сервисов (app, db, redis)
├── templates/                     # HTML шаблоны
│   ├── index.html                 # Главная страница
│   └── swagger.html               # Swagger UI
├── static/                        # Статические файлы
│   ├── style.css                  # Стили в стиле Bitrix24
│   └── app.js                     # JavaScript клиент
├── logs/                          # Логи приложения
├── data/                          # Данные (если нужны)
├── requirements.txt               # Python зависимости
└── README.md                      # Документация
```

## Быстрый старт

### С Docker (рекомендуется)

1. **Клонируйте репозиторий:**
```bash
git clone https://github.com/anveralidevelopment/mite-tmn.git
cd mite-tmn
```

2. **Запустите приложение:**
```bash
docker-compose -f docker/docker-compose.yml up -d --build
```

3. **Откройте в браузере:**
```
http://localhost:5000
```

4. **API документация:**
```
http://localhost:5000/api/docs
```

5. **Prometheus метрики:**
```
http://localhost:5000/api/metrics
```

### Локально (без Docker)

1. **Установите зависимости:**
```bash
pip install -r requirements.txt
```

2. **Настройте PostgreSQL и Redis** и создайте переменные окружения:
```bash
export DATABASE_URL=postgresql://user:password@localhost:5432/mite_tmn
export REDIS_URL=redis://localhost:6379/0
```

3. **Запустите приложение:**
```bash
cd src
python app.py
```

Или с Gunicorn:
```bash
cd src
gunicorn --bind 0.0.0.0:5000 --workers 2 app:app
```

## API Endpoints

### Основные endpoints

- `GET /` - Главная страница
- `GET /api/docs` - Swagger UI документация
- `GET /api/swagger.json` - Swagger JSON схема
- `GET /api/metrics` - Prometheus метрики

### Статистика

- `GET /api/stats` - Получение статистики (текущая/прошлая неделя)
  - **Response**: `{current_week: {cases, date, risk_level}, previous_week: {...}}`

### Источники данных

- `GET /api/sources` - Список источников данных с фильтрацией и пагинацией
  - **Query параметры**:
    - `limit` (int, default: 10) - Максимальное количество записей
    - `offset` (int, default: 0) - Смещение для пагинации
    - `search` (string) - Поисковый запрос
    - `location` (string) - Фильтр по локации
    - `source` (string) - Фильтр по источнику
    - `risk_level` (string) - Фильтр по уровню риска
    - `start_date` (YYYY-MM-DD) - Начальная дата
    - `end_date` (YYYY-MM-DD) - Конечная дата
  - **Response**: `{sources: [...], total: int, has_more: bool, filters_applied: {...}}`

### Графики и визуализация

- `GET /api/graph` - Данные для графика активности
  - **Query параметры**:
    - `start_date` (YYYY-MM-DD) - Начальная дата
    - `end_date` (YYYY-MM-DD) - Конечная дата
  - **Response**: `{weeks: [...], cases: [...], colors: [...]}`

- `GET /api/map-data` - Данные для интерактивной карты
  - **Query параметры**:
    - `view` (string: "all"|"week"|"month") - Период отображения
  - **Response**: `{locations: [{lat, lng, location, cases, date, source, title}]}`

### ML и прогнозы

- `GET /api/forecast` - Прогноз активности на 2026 год
  - **Response**: `{forecast: [{month, total_cases, avg_weekly}], weekly_forecast: [...]}`

- `GET /api/news-feed` - Лента новостей, сгенерированная ML
  - **Response**: `{news: [{text, date, location, cases, type, priority}], count: int}`

- `GET /api/ml/metrics` - Метрики качества ML моделей
  - **Response**: `{r2_score, rmse, mape, model_name}`

- `GET /api/ml/anomalies` - Обнаружение аномалий в данных
  - **Response**: `{anomalies: [{date, cases, location, score}]}`

- `GET /api/ml/clusters` - Кластеризация локаций по активности
  - **Response**: `{clusters: [{cluster_id, locations: [...], avg_cases}]}`

- `GET /api/ml/recommendations` - Рекомендации по профилактике
  - **Response**: `{recommendations: [{type, location, message, priority}]}`

- `POST /api/ml/ab-test` - Инициация A/B тестирования моделей
  - **Body**: `{model_a: "linear", model_b: "random_forest", duration_days: 7}`
  - **Response**: `{test_id, status}`

- `POST /api/ml/automl` - Автоматический выбор лучшей модели
  - **Response**: `{best_model, metrics, training_time}`

### Аналитика

- `GET /api/analytics/compare` - Сравнение с предыдущими годами
  - **Response**: `{comparison: {year: {total_cases, records_count, avg_per_month}}}`

### Экспорт данных

- `GET /api/export/csv` - Экспорт в CSV
  - **Query параметры**: `start_date`, `end_date` (опционально)
  - **Response**: Файл CSV для скачивания

- `GET /api/export/excel` - Экспорт в Excel
  - **Query параметры**: `start_date`, `end_date` (опционально)
  - **Response**: Файл Excel для скачивания

- `GET /api/export/pdf` - Экспорт в PDF
  - **Query параметры**: `start_date`, `end_date` (опционально)
  - **Response**: Файл PDF для скачивания

### Управление

- `POST /api/update` - Запуск обновления данных из всех источников
  - **Response**: `{status: "started", message: "..."}`

## Дизайн

Интерфейс выполнен в стиле Bitrix24:

### Цветовая палитра
- **Синие тона**:
  - Основной: `#2066B0`
  - Темный: `#185a9a`
  - Светлый: `#2e7cd6`
- **Зеленые акценты**:
  - Основной: `#00c853`
  - Светлый: `#00e676`
  - Темный: `#00a844`
- **Дополнительные**:
  - Предупреждение: `#ffd600`
  - Опасность: `#d32f2f`
  - Успех: `#00c853`

### Темная тема
- Переключение через кнопку в шапке
- Сохранение выбора в localStorage
- Адаптивные цвета для всех элементов

## Конфигурация

Настройки находятся в `config/config.json`:

```json
{
  "app": {
    "title": "Монитор активности клещей - Тюмень",
    "version": "2.0"
  },
  "parsing": {
    "sources": {
      "web": {...},
      "telegram": {...},
      "rospotrebnadzor_news": {...},
      "tyumen_news": {...},
      "vk_tyumen": {...},
      "local_news": {...},
      "medical_api": {...},
      "weather_api": {...}
    },
    "timeout": 15,
    "retry_count": 3,
    "retry_delay": 2,
    "auto_update_interval_minutes": 1440
  },
  "risk_levels": {
    "low": {"threshold": 50, "color": "#00ff00"},
    "moderate": {"threshold": 100, "color": "#ffff00"},
    "high": {"threshold": 150, "color": "#ff9900"},
    "very_high": {"threshold": 999999, "color": "#ff0000"}
  },
  "cache": {
    "enabled": true,
    "default_timeout": 300
  },
  "mail": {
    "enabled": false,
    "server": "smtp.gmail.com",
    "port": 587,
    "username": "",
    "password": "",
    "recipients": []
  },
  "telegram": {
    "bot": {
      "enabled": false,
      "token": "",
      "chat_ids": []
    }
  },
  "notifications": {
    "spike_threshold": 1.5,
    "high_activity_threshold": 10,
    "enabled": true
  }
}
```

### Важные настройки

- **auto_update_interval_minutes**: 1440 (24 часа) - интервал автоматического обновления данных
- **Проверка сезонности**: автоматически включена, регистрация случаев только с 20 апреля по 10 октября

## База данных

### PostgreSQL

Приложение использует PostgreSQL для хранения данных. Таблицы создаются автоматически при первом запуске.

**Схема таблицы `tick_data`:**
- `id` - Первичный ключ
- `date` - Дата записи (индексировано)
- `cases` - Количество случаев
- `risk_level` - Уровень риска (Низкий, Умеренный, Высокий, Очень высокий) (индексировано)
- `source` - Источник данных (индексировано)
- `title` - Заголовок статьи/новости
- `content` - Полное содержимое
- `url` - URL источника (индексировано)
- `location` - Название населенного пункта (индексировано)
- `created_at` - Дата создания записи (индексировано)
- `updated_at` - Дата обновления записи

**Индексы:**
- Индексы на отдельных колонках: `date`, `risk_level`, `source`, `url`, `location`, `created_at`
- Составные индексы: `(date, source)`, `(date, location)`, `(date, risk_level)`, `(source, location)`

### Подключение к БД в Docker:

```bash
docker-compose -f docker/docker-compose.yml exec db psql -U mite_user -d mite_tmn
```

## ML модели

### Используемые модели

1. **Linear Regression** - линейная регрессия для базовых прогнозов
2. **Random Forest** - случайный лес для учета нелинейных зависимостей
3. **XGBoost** - градиентный бустинг для более точных прогнозов
4. **LSTM** - долгосрочная память для временных рядов (если установлен TensorFlow)
5. **GRU** - упрощенная версия LSTM (если установлен TensorFlow)
6. **Ensemble** - комбинация нескольких моделей для улучшения точности

### Алгоритм обучения

1. Данные группируются по неделям
2. Используется скользящее окно из 4 недель для предсказания следующей
3. Данные нормализуются через StandardScaler
4. Обучаются все доступные модели
5. Выбирается лучшая модель по метрике MAE (Mean Absolute Error)
6. Для улучшения прогнозов используются данные о погоде и календарных событиях

### Метрики качества

- **R² (коэффициент детерминации)** - доля дисперсии, объясняемая моделью
- **RMSE (Root Mean Squared Error)** - среднеквадратичная ошибка
- **MAPE (Mean Absolute Percentage Error)** - средняя абсолютная процентная ошибка

### Генерация новостей

ML анализирует данные за последние 30 дней и генерирует новости:
- Всплески активности по локациям
- Всплески за день
- Растущие тренды
- Сводки по районам

### Обнаружение аномалий

ML модель анализирует исторические данные и выявляет необычные паттерны:
- Резкие скачки активности
- Неожиданные изменения в определенных локациях
- Отклонения от сезонных трендов

### Кластеризация локаций

Автоматическая группировка районов по схожим паттернам активности для:
- Выявления зон риска
- Оптимизации профилактических мер
- Анализа территориальных особенностей

### Рекомендации по профилактике

На основе анализа данных ML генерирует рекомендации:
- Когда начинать профилактику в конкретном районе
- Интенсивность профилактических мер
- Специфические советы для каждой локации

## Мониторинг

### Prometheus метрики

Доступны по адресу `/api/metrics`:

- `http_requests_total` - Общее количество HTTP запросов
- `http_request_duration_seconds` - Время выполнения запросов
- `active_users` - Количество активных пользователей
- `data_points_total` - Общее количество точек данных в БД
- `cache_hits_total` - Попадания в кэш
- `cache_misses_total` - Промахи кэша
- `parsing_errors_total` - Ошибки парсинга по источникам
- `ml_predictions_total` - Количество ML прогнозов

### Интеграция с Grafana

Метрики можно визуализировать в Grafana:
1. Настроить Prometheus как источник данных
2. Импортировать дашборды для мониторинга приложения

## Настройка уведомлений

### Email уведомления

1. Включите в `config/config.json`:
```json
"mail": {
  "enabled": true,
  "server": "smtp.gmail.com",
  "port": 587,
  "use_tls": true,
  "username": "your-email@gmail.com",
  "password": "your-app-password",
  "from": "your-email@gmail.com",
  "recipients": ["recipient@example.com"]
}
```

### Telegram уведомления

1. Создайте бота через @BotFather в Telegram
2. Получите токен бота
3. Включите в `config/config.json`:
```json
"telegram": {
  "bot": {
    "enabled": true,
    "token": "YOUR_BOT_TOKEN",
    "chat_ids": ["YOUR_CHAT_ID"]
  }
}
```

## Docker

### Сервисы

- **app** - Flask приложение (порт 5000)
- **db** - PostgreSQL 15 (порт 5432)
- **redis** - Redis 7 (порт 6379)

### Команды

**Запуск:**
```bash
docker-compose -f docker/docker-compose.yml up -d --build
```

**Остановка:**
```bash
docker-compose -f docker/docker-compose.yml down
```

**Остановка с удалением данных:**
```bash
docker-compose -f docker/docker-compose.yml down -v
```

**Полная очистка (образы и кэш):**
```bash
docker-compose -f docker/docker-compose.yml down -v
docker system prune -a --volumes -f
docker-compose -f docker/docker-compose.yml build --no-cache
docker-compose -f docker/docker-compose.yml up -d
```

**Просмотр логов:**
```bash
docker-compose -f docker/docker-compose.yml logs -f app
```

**Перезапуск:**
```bash
docker-compose -f docker/docker-compose.yml restart app
```

## Логирование

Логи сохраняются в директории `logs/`:
- `app.log` - основной лог файл
- Автоматическая ротация (максимум 10MB, 5 файлов)

Уровни логирования настраиваются в `config/config.json`.

## Безопасность

- **Rate limiting** - ограничение количества запросов
- **CORS** - настройка кросс-доменных запросов
- **JWT** - поддержка аутентификации (опционально)
- **Валидация данных** - проверка входных данных перед сохранением
- **Проверка сезонности** - автоматическое отсеивание данных вне сезона активности клещей

## Автоматическое обновление

Приложение автоматически обновляет данные раз в сутки (1440 минут, настраивается в `config.json`).

После каждого обновления:
1. Парсятся все источники данных
2. Данные валидируются и проверяются на сезонность
3. Дубликаты обнаруживаются и обрабатываются
4. Данные сохраняются в БД
5. ML модель переобучается на новых данных
6. Кэш очищается для обновленных данных

### Проверка сезонности

Приложение автоматически проверяет, что регистрируемые случаи укусов клещей попадают в сезон активности (с 20 апреля по 10 октября). Данные вне этого периода автоматически отсеиваются при валидации.

## Производительность

- **Кэширование** - Redis кэш для часто запрашиваемых данных
- **Оптимизация запросов** - индексы в БД для быстрого поиска
- **Составные индексы** - оптимизация сложных запросов с фильтрами
- **Асинхронная обработка** - парсинг выполняется в фоновых потоках
- **Rate limiting** - защита от перегрузки сервера
- **Пагинация** - эффективная загрузка больших объемов данных

## Технологии

### Backend
- **Flask** - веб-фреймворк
- **SQLAlchemy** - ORM для работы с БД
- **PostgreSQL** - база данных
- **Redis** - кэширование
- **Gunicorn** - WSGI сервер

### ML и Data Science
- **scikit-learn** - ML модели (Linear Regression, Random Forest)
- **XGBoost** - градиентный бустинг
- **TensorFlow/Keras** - глубокое обучение (LSTM, GRU)
- **pandas** - обработка данных
- **numpy** - численные вычисления
- **scipy** - научные вычисления

### Frontend
- **Chart.js** - интерактивные графики
- **Leaflet.js** - интерактивные карты
- **Vanilla JavaScript** - клиентская логика

### Парсинг
- **BeautifulSoup** - парсинг HTML
- **feedparser** - парсинг RSS
- **requests** - HTTP запросы
- **fake-useragent** - ротация User-Agent
- **Selenium** - парсинг JS-сайтов
- **PyPDF2** - парсинг PDF
- **pytesseract** - OCR для изображений

### Мониторинг
- **Prometheus Client** - экспорт метрик
- **Flask-Limiter** - rate limiting

### Документация
- **Swagger UI** - интерактивная API документация

## Лицензия

Проект предназначен для личного использования.

## Разработка

Разработано в [Анверали](https://anverali.ru/)

## Ссылки

- **Веб-интерфейс**: http://localhost:5000
- **API документация**: http://localhost:5000/api/docs
- **Prometheus метрики**: http://localhost:5000/api/metrics
- **Swagger JSON**: http://localhost:5000/api/swagger.json

## Поддержка

При возникновении проблем проверьте:
1. Логи приложения: `docker-compose -f docker/docker-compose.yml logs app`
2. Логи БД: `docker-compose -f docker/docker-compose.yml logs db`
3. Логи Redis: `docker-compose -f docker/docker-compose.yml logs redis`
4. Статус контейнеров: `docker-compose -f docker/docker-compose.yml ps`
